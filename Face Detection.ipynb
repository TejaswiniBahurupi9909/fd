{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Collecting Samples Complete!!!\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('C:/Users/admin/Anaconda3/Lib/site-packages/cv2/data/haarcascade_frontalface_alt.xml')\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    if faces is():\n",
    "        return None\n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h,x:x+w]\n",
    "        \n",
    "        return cropped_face\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count+=1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path = 'E:/ml/IMAGES_EG/'+'Zeel'+str(count)+'.jpg'\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        \n",
    "        \n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow('Face Copper',face)\n",
    "\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"Face not Found\")\n",
    "        pass \n",
    "\n",
    "    if cv2.waitKey(1)==13 or count==100:\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Collecting Samples Complete!!!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-04224fc6e986>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-04224fc6e986>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    def face_detector(img,size-0.5):\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Training Complete!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "\n",
    "\n",
    "data_path='E:/ml/IMAGES_EG/'\n",
    "onlyfiles =[f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "Training_Data,Labels= [],[]\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "    \n",
    "Labels=np.asarray(Labels,dtype=np.int32)\n",
    "model=cv2.face.LBPHFaceRecognizer_create()\n",
    "model=cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"model Training Complete!!!!!!!!\")\n",
    "#print(model)\n",
    "#print(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 42.365872175193864\n",
      "164\n",
      "152 42.33720050005698\n",
      "152\n",
      "159 42.19498351293103\n",
      "159\n",
      "160 43.18582061079918\n",
      "160\n",
      "148 42.1639926692837\n",
      "148\n",
      "151 42.70837908925811\n",
      "151\n",
      "105 42.90705098731145\n",
      "105\n",
      "105 42.2813931526548\n",
      "105\n",
      "160 41.77099671220512\n",
      "160\n",
      "178 42.67431595507482\n",
      "178\n",
      "151 42.82323417482554\n",
      "151\n",
      "151 42.68164376826764\n",
      "151\n",
      "105 42.78516433002035\n",
      "105\n",
      "105 42.47470588483857\n",
      "105\n",
      "151 42.8903804691908\n",
      "151\n",
      "151 42.84810064666851\n",
      "151\n",
      "105 42.561139454053425\n",
      "105\n",
      "148 42.58055659547044\n",
      "148\n",
      "178 43.151441487901714\n",
      "178\n",
      "105 43.24218004698436\n",
      "105\n",
      "161 43.150235347371066\n",
      "161\n",
      "112 42.4467452185753\n",
      "112\n",
      "160 42.30273493033807\n",
      "160\n",
      "100 43.01059873104581\n",
      "100\n",
      "160 45.33156053315848\n",
      "160\n",
      "100 44.036397711365815\n",
      "100\n",
      "160 44.39192482526742\n",
      "160\n",
      "160 46.01587736323539\n",
      "160\n",
      "160 45.856458827069375\n",
      "160\n",
      "100 43.89096105627401\n",
      "100\n",
      "160 44.81586019990186\n",
      "160\n",
      "100 45.3874194110731\n",
      "100\n",
      "100 46.32758006143182\n",
      "100\n",
      "100 44.71262099519491\n",
      "100\n",
      "100 43.91860694083334\n",
      "100\n",
      "100 44.06853948053143\n",
      "100\n",
      "160 44.12841957656804\n",
      "160\n",
      "100 44.98295585321538\n",
      "100\n",
      "160 43.32182204872875\n",
      "160\n",
      "160 43.19599312374602\n",
      "160\n",
      "100 43.07638722719258\n",
      "100\n",
      "160 43.43977167405747\n",
      "160\n",
      "159 43.028784738346054\n",
      "159\n",
      "105 42.939195119284854\n",
      "105\n",
      "105 42.709182425224014\n",
      "105\n",
      "160 43.35774310025757\n",
      "160\n",
      "112 44.5111651703052\n",
      "112\n",
      "105 43.874759771640676\n",
      "105\n",
      "105 42.709786138358616\n",
      "105\n",
      "100 45.22011123399586\n",
      "100\n",
      "100 46.01750989728859\n",
      "100\n",
      "100 44.68337106751994\n",
      "100\n",
      "100 44.4315510176032\n",
      "100\n",
      "100 43.91390046755677\n",
      "100\n",
      "100 46.32775359395256\n",
      "100\n",
      "100 44.466783802482226\n",
      "100\n",
      "105 43.78816101149761\n",
      "105\n",
      "100 43.15911003735821\n",
      "100\n",
      "159 44.281715315404206\n",
      "159\n",
      "100 44.375815539039245\n",
      "100\n",
      "148 42.429735658904754\n",
      "148\n",
      "100 43.6087400712242\n",
      "100\n",
      "148 43.44551856879872\n",
      "148\n",
      "148 42.62976991324136\n",
      "148\n",
      "102 42.444429470791356\n",
      "102\n",
      "148 42.73119810047103\n",
      "148\n",
      "102 41.974326481254685\n",
      "102\n",
      "102 43.10141005822708\n",
      "102\n",
      "105 43.441816149497456\n",
      "105\n",
      "148 43.39105036688742\n",
      "148\n",
      "106 44.23026226459157\n",
      "106\n",
      "100 44.3387003150244\n",
      "100\n",
      "148 44.09444422541958\n",
      "148\n",
      "105 44.18549662675079\n",
      "105\n",
      "173 45.22481132425995\n",
      "173\n",
      "102 44.29700573510802\n",
      "102\n",
      "105 45.755158780319135\n",
      "105\n",
      "174 44.617947475270675\n",
      "174\n",
      "105 45.918348119020166\n",
      "105\n",
      "105 44.79857547344202\n",
      "105\n",
      "105 43.88011653571678\n",
      "105\n",
      "174 44.159436203564155\n",
      "174\n",
      "160 45.03816513718207\n",
      "160\n",
      "100 43.42312986088077\n",
      "100\n",
      "100 42.82768646445545\n",
      "100\n",
      "100 43.48915101376441\n",
      "100\n",
      "100 44.45484995946674\n",
      "100\n",
      "160 44.66110240840517\n",
      "160\n",
      "100 44.615839708083946\n",
      "100\n",
      "100 44.70742688636199\n",
      "100\n",
      "160 44.26299283978463\n",
      "160\n",
      "160 43.700918171909805\n",
      "160\n",
      "100 44.086842462202135\n",
      "100\n",
      "105 41.927640604205656\n",
      "105\n",
      "105 42.6039869836262\n",
      "105\n",
      "177 44.2499760490097\n",
      "177\n",
      "105 44.23973669821636\n",
      "105\n",
      "102 44.08201551108726\n",
      "102\n",
      "102 44.19130000014121\n",
      "102\n",
      "102 46.264586467554935\n",
      "102\n",
      "106 45.24197039617803\n",
      "106\n",
      "105 44.94192480240408\n",
      "105\n",
      "105 44.71010643290112\n",
      "105\n",
      "100 44.452188157154616\n",
      "100\n",
      "100 45.72232304908837\n",
      "100\n",
      "100 45.36566176031494\n",
      "100\n",
      "100 44.01457881216376\n",
      "100\n",
      "100 44.973587964875065\n",
      "100\n",
      "100 46.916650840015244\n",
      "100\n",
      "100 44.9850204251698\n",
      "100\n",
      "175 45.24340995533131\n",
      "175\n",
      "100 45.30637626967387\n",
      "100\n",
      "178 46.57888575823597\n",
      "178\n",
      "178 48.2336577358393\n",
      "178\n",
      "196 43.99800117038984\n",
      "196\n",
      "196 43.52755339592706\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "face_classifier = cv2.CascadeClassifier('C:/Users/admin/Anaconda3/Lib/site-packages/cv2/data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "def face_detector (img, size=0.5):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    if faces is():\n",
    "        return img,[]\n",
    "    \n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi,(200,200))\n",
    "        return img,roi\n",
    "    \n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "    image,face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face)\n",
    "        print(*result)\n",
    "        print(result[0])\n",
    "        \n",
    "        if result[1] < 500:\n",
    "            confidence = int(100*(1-(result[1])/300))\n",
    "            display_string = str(confidence)+'% Confidencit is user'\n",
    "\n",
    "        cv2.putText(image,display_string,(100,120), cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2) \n",
    "        if confidence < 85:\n",
    "            cv2.putText(image, \"Unblocked\", (250,450), cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "    \n",
    "        else :\n",
    "            cv2.putText(image, \"Locked\", (250,450), cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow('Face Cropper', image)\n",
    "    \n",
    "    except:\n",
    "        cv2.putText(image, \"Face Not Found\", (250,450), cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "    \n",
    "        cv2.imshow('Face Cropper', image)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183 149  81 ...  18  18  17]\n",
      " [172 125  66 ...  17  16  16]\n",
      " [161  92  46 ...  16  16  17]\n",
      " ...\n",
      " [ 26  25  24 ...  25  43  70]\n",
      " [ 23  25  24 ...  21  31  40]\n",
      " [ 23  25  23 ...  24  32  43]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"E:/ml/IMAGES_EG/Kshitij14.jpg\",0)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49 30 27 ... 13 11 10]\n",
      " [34 22 21 ... 10 10  9]\n",
      " [27 23 28 ...  9  9 10]\n",
      " ...\n",
      " [28 26 23 ... 28 29 32]\n",
      " [28 27 25 ... 31 30 27]\n",
      " [31 31 28 ... 29 27 20]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "img = cv2.imread(\"E:/ml/IMAGES_EG/Kshitij15.jpg\",0)\n",
    "np_img = np.array(img)\n",
    "print(np_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
